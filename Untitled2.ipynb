{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2mqG/XJcdZjY75uoh/djR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luycass/The-Broken-bond-IA-gerenciadora-/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando o SDK do Google"
      ],
      "metadata": {
        "id": "7yRD9fQHrftt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExD5Xq_AbEAh"
      },
      "outputs": [],
      "source": [
        "# !pip install -q -U google.generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importa a base de dados do google\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get(\"SECRET_KEY\")\n",
        "genai.configure(api_key = api_key)\n"
      ],
      "metadata": {
        "id": "_ubcCUdfry-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\"gemine-pro\")"
      ],
      "metadata": {
        "id": "1FbGjJ6ssEph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listando os modelos disponiveis do Google"
      ],
      "metadata": {
        "id": "xdtxZ43zsGUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "# \"generateContent\" = atributo que gera conteudo\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "id": "nvXI3FTfsMZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurando nosso modelo de ChatBot"
      ],
      "metadata": {
        "id": "0NtwtqXRsZGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "# TEMPERATURA / QUANTO MAIOR O MUMERO MAIS IA + CRIATIVA\n",
        "# TEMPERATURA / QUANTO MENOR O NUMERO MAIS IA + PROFISIONAL/FORMAL\n",
        "\n",
        "generation_config = {\n",
        "  \"temperature\": 0.5,\n",
        "  \"candidate_count\": 1, # 1° OPÇÃO DE RESPOSTA\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "8y8rdVQisdla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK_NONE = BLOQUEAR NADA\n",
        "# BLOCK_FREW = BLOQUEAR POUCO\n",
        "# BLOCK_SOME = BLOQUEAR VARIOS\n",
        "# BLOCK_MOST = BLOQUEAR TODOS\n",
        "\n",
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\" ,\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "}"
      ],
      "metadata": {
        "id": "WuTFfrowsjxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando nosso modelo"
      ],
      "metadata": {
        "id": "ZLFA_pOLsqeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GenerativeModel = modelo generativo\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)\n"
      ],
      "metadata": {
        "id": "9nbpOywSstvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Que empresa criou o modelo de IA Gemini?\")\n",
        "response.text"
      ],
      "metadata": {
        "id": "YYFv7AWis0hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])\n",
        "\n",
        "prompt = input('Esperando prompt: ')\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"Resposta:\", response.text, '\\n\\n')\n",
        "  prompt = input('Esperando prompt: ')\n",
        "\n",
        "  import speech_recognition as sr\n",
        "\n",
        "# Função para converter áudio em texto\n",
        "def audio_to_text():\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"Por favor, fale algo...\")\n",
        "        audio = recognizer.listen(source)\n",
        "\n",
        "    try:\n",
        "        text = recognizer.recognize_google(audio, language='pt-BR')\n",
        "        print(\"Você disse:\", text)\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Não foi possível entender o áudio.\")\n",
        "        return \"\"\n",
        "    except sr.RequestError as e:\n",
        "        print(\"Erro ao fazer a requisição ao serviço de reconhecimento de fala; {0}\".format(e))\n",
        "        return \"\"\n",
        "\n",
        "# Substitua a parte do código onde você solicita o prompt pelo seguinte:\n",
        "prompt = input('Esperando prompt (Digite \"texto\" para entrada de texto ou \"audio\" para entrada de áudio): ')\n",
        "\n",
        "if prompt.lower() == \"audio\":\n",
        "    prompt = audio_to_text()\n",
        "\n",
        "import PyPDF2\n",
        "\n",
        "# Função para extrair texto de um arquivo PDF\n",
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Substitua a parte do código onde você solicita o prompt pelo seguinte:\n",
        "prompt = input('Esperando prompt (Digite \"texto\" para entrada de texto, \"audio\" para entrada de áudio, ou \"arquivo\" para inserir um arquivo): ')\n",
        "\n",
        "if prompt.lower() == \"audio\":\n",
        "    prompt = audio_to_text()\n",
        "elif prompt.lower() == \"arquivo\":\n",
        "    file_path = input(\"Digite o caminho para o arquivo PDF: \")\n",
        "    prompt = extract_text_from_pdf(file_path)\n",
        "\n",
        "# Substitua a parte do código onde você solicita o prompt pelo seguinte:\n",
        "prompt_type = input('Esperando prompt (Digite \"texto\" para entrada de texto, \"audio\" para entrada de áudio ou \"arquivo\" para inserir um arquivo): ')\n",
        "\n",
        "if prompt_type.lower() == \"texto\":\n",
        "    prompt = input(\"Digite o texto: \")\n",
        "elif prompt_type.lower() == \"audio\":\n",
        "    prompt = audio_to_text()\n",
        "elif prompt_type.lower() == \"arquivo\":\n",
        "    file_path = input(\"Digite o caminho para o arquivo PDF: \")\n",
        "    prompt = extract_text_from_pdf(file_path)\n",
        "else:\n",
        "    print(\"Opção inválida. Por favor, escolha entre 'texto', 'audio' ou 'arquivo'.\")\n",
        "    prompt = \"\""
      ],
      "metadata": {
        "id": "cm67gPaCs9Mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deixando nosso modelo mais \"Bonitinho\""
      ],
      "metadata": {
        "id": "doOrC0n2tSBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Melhorando a visualização\n",
        "#Código disponível em https://ai.google.dev/tutorials/python_quickstart#import_packages\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "#Imprimindo o histórico\n",
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "  print('-------------------------------------------')"
      ],
      "metadata": {
        "id": "l36wFVj7tXHc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}